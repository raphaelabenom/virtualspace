{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando texto com ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "chat = ChatOllama(model='llama3:8b-instruct-q2_k')\n",
    "resposta = chat.invoke('Olá')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tudo bem?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Por aqui!\\n\\nPor que o processador decidiu ir ao médico?\\nEle estava sentindo um bug!\\n\\nE por isso, o programador resolveu mudar a linguagem do seu laptop...\\nPara evitar conflitos entre ele e os bytes!\\n\\nO que um byte vale em uma moça?\\nUma linha é um arquivo é um caractere é um... Ah, você sabia!\\nOra, qual é o problema com você? \\nVocê está trabalhando em um loop infinito?\\n\\nQual é o seu favorito tipo de dados? \\nGeralmente, é um array, mas às vezes é um lista...\\nE quando ele não tem motivos?\\nBem, lá está a questão!\\n\\nO que a memória RAM faz com sua liberdade?\\nEla simplesmente não quer ser relembrada!\\nE por isso, o programador resolveu comprar um pen drive...\\nPara ter sempre as coisas sob controle!\\n\\nO que é o tempo de processamento em uma moça?\\nBem, lá está a questão! \\nEle está trabalhando em um loop infinito...', response_metadata={'model': 'llama3:8b-instruct-q2_k', 'created_at': '2024-07-11T18:10:08.1271048Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 136488868600, 'load_duration': 36428600, 'prompt_eval_count': 34, 'prompt_eval_duration': 11455120000, 'eval_count': 228, 'eval_duration': 124994478000}, id='run-c36ccf15-5203-4b0c-908b-5288a3c711d0-0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "mesages = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'Voce é um assistente engraçado'),\n",
    "    ('human', 'Faça uma piada sobre: {algo}')\n",
    "])\n",
    "\n",
    "chain = mesages | chat\n",
    "\n",
    "resposta = chain.invoke({'algo': 'computação'})\n",
    "resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Por aqui!\n",
      "\n",
      "Por que o processador decidiu ir ao médico?\n",
      "Ele estava sentindo um bug!\n",
      "\n",
      "E por isso, o programador resolveu mudar a linguagem do seu laptop...\n",
      "Para evitar conflitos entre ele e os bytes!\n",
      "\n",
      "O que um byte vale em uma moça?\n",
      "Uma linha é um arquivo é um caractere é um... Ah, você sabia!\n",
      "Ora, qual é o problema com você? \n",
      "Você está trabalhando em um loop infinito?\n",
      "\n",
      "Qual é o seu favorito tipo de dados? \n",
      "Geralmente, é um array, mas às vezes é um lista...\n",
      "E quando ele não tem motivos?\n",
      "Bem, lá está a questão!\n",
      "\n",
      "O que a memória RAM faz com sua liberdade?\n",
      "Ela simplesmente não quer ser relembrada!\n",
      "E por isso, o programador resolveu comprar um pen drive...\n",
      "Para ter sempre as coisas sob controle!\n",
      "\n",
      "O que é o tempo de processamento em uma moça?\n",
      "Bem, lá está a questão! \n",
      "Ele está trabalhando em um loop infinito...\n"
     ]
    }
   ],
   "source": [
    "print(resposta.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando uma stream de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Por aqui, em lugar de uma linguagem de programação ser chamada \"Python\"...\n",
      "\n",
      "Uma linguagem de programação que está sempre no seu pé!\n",
      "\n",
      "* Por isso, quando você pergunta o que ela fazia ontem...\n",
      "  Você não precisa perguntar mais nada!\n",
      "  A linguagem Python fazia um burrito\n",
      "\n",
      "* E agora, é hora do Python dar um show...\n",
      "* Mas, atirei na culatra, porque ele sempre se escondera!\n",
      "\n",
      "E assim, no Python é o rei da linguagem...\n",
      "* Foi o que aconteceu quando eu perguntei...\n",
      "\n",
      "(Nota: Essas piadas são uma espécie de \"um dobro\" do que a gente fazia no Brasil. Eles são um tipo de piada"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "mesages = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'Voce é um assistente engraçado'),\n",
    "    ('human', 'Faça uma piada sobre: {algo}')\n",
    "])\n",
    "\n",
    "chain = mesages | chat\n",
    "\n",
    "stream = chain.stream({'algo': 'programação python'})\n",
    "for chunk in stream:\n",
    "    print(chunk.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
